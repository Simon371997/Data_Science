{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "\n",
      "[3 rows x 31 columns]\n",
      "Shape of X: (80000, 28)\n",
      "Shape of y: (80000,)\n",
      "Fraud Cases: 196\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./tutorial_data/creditcard.csv')[:80000]\n",
    "print(df.head(3))\n",
    "\n",
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "\n",
    "\n",
    "print(f'Shape of X: {X.shape}')\n",
    "print(f'Shape of y: {y.shape}')\n",
    "print(f'Fraud Cases: {y.sum()}')\n",
    "# unbalanced Dataset (just 196 Fraud Cases in 80.000 entries) (0 = non fraud, 1 = fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mod = LogisticRegression(class_weight ={0:1, 1:2} ,max_iter=1000) #\n",
    "mod.fit(X, y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mod = LogisticRegression(class_weight ={0:1, 1:2} ,max_iter=1000) #\n",
    "mod.fit(X, y).predict(X).sum()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0:1, 1:v} for v in range(1,4)]},\n",
    "    cv = 4\n",
    ")\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       1.394206      0.072633         0.005563        0.001752   \n",
      "1       1.338704      0.671255         0.007093        0.003436   \n",
      "2       2.441844      0.420996         0.011762        0.004497   \n",
      "\n",
      "  param_class_weight                          params  split0_test_score  \\\n",
      "0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}            0.99405   \n",
      "1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}            0.99025   \n",
      "2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}            0.98730   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
      "0            0.99835            0.99945            0.99780         0.997413   \n",
      "1            0.99840            0.99960            0.99805         0.996575   \n",
      "2            0.99845            0.99960            0.99815         0.995875   \n",
      "\n",
      "   std_test_score  rank_test_score  \n",
      "0        0.002030                1  \n",
      "1        0.003697                2  \n",
      "2        0.004980                3  \n"
     ]
    }
   ],
   "source": [
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "print(grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Der Acc-Score ist sehr gut aber vermutlich nur weil es kaum Frauds in den Datem gibt und da Modell das auch predicted\n",
    "#### Deshalb wäre es sinnvoll eine andere Metrik zu nutzten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.851581      0.180361         0.018123        0.001126   \n",
      "1       0.811322      0.210956         0.018546        0.001301   \n",
      "2       0.893184      0.134789         0.020220        0.001535   \n",
      "\n",
      "  param_class_weight                          params  split0_test_precision  \\\n",
      "0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}               0.281250   \n",
      "1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}               0.190678   \n",
      "2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}               0.154882   \n",
      "\n",
      "   split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
      "0                    1.0               0.952381               0.857143  ...   \n",
      "1                    1.0               0.955556               0.812500  ...   \n",
      "2                    1.0               0.955556               0.800000  ...   \n",
      "\n",
      "   split3_test_recall_score  mean_test_recall_score  std_test_recall_score  \\\n",
      "0                  0.122449                0.545918               0.331397   \n",
      "1                  0.265306                0.602041               0.297672   \n",
      "2                  0.326531                0.627551               0.281816   \n",
      "\n",
      "   rank_test_recall_score  split0_train_recall_score  \\\n",
      "0                       3                   0.863946   \n",
      "1                       2                   0.870748   \n",
      "2                       1                   0.870748   \n",
      "\n",
      "   split1_train_recall_score  split2_train_recall_score  \\\n",
      "0                   0.585034                   0.530612   \n",
      "1                   0.659864                   0.632653   \n",
      "2                   0.714286                   0.680272   \n",
      "\n",
      "   split3_train_recall_score  mean_train_recall_score  std_train_recall_score  \n",
      "0                   0.693878                 0.668367                0.127301  \n",
      "1                   0.782313                 0.736395                0.095889  \n",
      "2                   0.816327                 0.770408                0.076568  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0:1, 1:v} for v in np.linspace(1, 20, 30)]},\n",
    "    scoring = {'precision':make_scorer(precision_score), 'recall_score':make_scorer(recall_score)},\n",
    "    refit='precision',\n",
    "    return_train_score=True, \n",
    "    cv = 10\n",
    ")\n",
    "grid.fit(X, y)\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0929711d380e35192f4cb7fc35982659e488768c1797b656fc22286d7128f20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
